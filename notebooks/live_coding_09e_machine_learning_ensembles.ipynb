{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6128f2b2-403b-488e-9a4e-44a791ff5e56",
   "metadata": {},
   "source": [
    "# Ensemble Models and Outlook\n",
    "\n",
    "In the past chapters, several common machine learning algorithms were introduced. They come with different strengths and weaknesses. And, although the code execution always looks very similar, they all require different parameters and adjustments.\n",
    "\n",
    "Before we move on to the next topic, let us introduce a very generally applicable trick in machine learning: **ensemble learning**. \n",
    "\n",
    "Ensemble learning is a method where multiple models, often called \"weak learners,\" are trained and combined to solve the same problem. The key idea is that by combining multiple models, we can achieve better performance than any single model alone. This idea is simple, yet in practice, ensemble models are surprisingly effective. There are two main types of ensemble methods: bagging and boosting.\n",
    "\n",
    "We will apply some common strategies to the data from the last chapter on predicting obesity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeaf5a13-2aad-4384-9ba9-d002573338ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b39858-2bf0-46ec-8ad7-b77a07c7458a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>...</th>\n",
       "      <th>CAEC_no</th>\n",
       "      <th>CALC_Always</th>\n",
       "      <th>CALC_Frequently</th>\n",
       "      <th>CALC_Sometimes</th>\n",
       "      <th>CALC_no</th>\n",
       "      <th>MTRANS_Automobile</th>\n",
       "      <th>MTRANS_Bike</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  NCP  \\\n",
       "0  21.0    1.62    64.0                               1     0   2.0  3.0   \n",
       "1  21.0    1.52    56.0                               1     0   3.0  3.0   \n",
       "2  23.0    1.80    77.0                               1     0   2.0  3.0   \n",
       "3  27.0    1.80    87.0                               0     0   3.0  3.0   \n",
       "4  22.0    1.78    89.8                               0     0   2.0  1.0   \n",
       "\n",
       "   SMOKE  CH2O  SCC  ...  CAEC_no  CALC_Always  CALC_Frequently  \\\n",
       "0      0   2.0    0  ...    False        False            False   \n",
       "1      1   3.0    1  ...    False        False            False   \n",
       "2      0   2.0    0  ...    False        False             True   \n",
       "3      0   2.0    0  ...    False        False             True   \n",
       "4      0   2.0    0  ...    False        False            False   \n",
       "\n",
       "   CALC_Sometimes  CALC_no  MTRANS_Automobile  MTRANS_Bike  MTRANS_Motorbike  \\\n",
       "0           False     True              False        False             False   \n",
       "1            True    False              False        False             False   \n",
       "2           False    False              False        False             False   \n",
       "3           False    False              False        False             False   \n",
       "4            True    False              False        False             False   \n",
       "\n",
       "   MTRANS_Public_Transportation  MTRANS_Walking  \n",
       "0                          True           False  \n",
       "1                          True           False  \n",
       "2                          True           False  \n",
       "3                         False            True  \n",
       "4                          True           False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"../datasets/obesity_dataset.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "mask = data.describe(include=\"all\").loc[\"unique\"] == 2\n",
    "binary_columns = data.columns[mask]\n",
    "data[binary_columns] = data[binary_columns].replace({'no': 0, 'yes': 1})\n",
    "\n",
    "y = data.NObeyesdad\n",
    "X = data.drop([\"NObeyesdad\"], axis=1)\n",
    "\n",
    "X = pd.get_dummies(X) #, prefix='', prefix_sep='')\n",
    "X = X.drop([\"Gender_Male\"], axis=1)  # not necessary, because here it is either Male or Female\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2aedb42-b207-42c9-8436-2580bc2ef4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976e335-ffbf-4c43-8654-58ff4ff8ea83",
   "metadata": {},
   "source": [
    "### Single Decision Tree\n",
    "Let's start again with a single decision tree, here with a set max_depth.\n",
    "As we saw in the last chapter, such a model works OK-ish on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a10f735-baa7-405e-84bf-473430ddfb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize base classifier\n",
    "tree = DecisionTreeClassifier(max_depth=6)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of Decision Tree Classifier: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712b9c10-2933-4fda-86e2-2399fa4f8986",
   "metadata": {},
   "source": [
    "## Bagging (Bootstrap Aggregating)\n",
    "\n",
    "Bagging is a technique that involves training multiple models on different subsets of the training data and then combining their predictions. Each subset is created by randomly sampling the training data with replacement (bootstrap sampling). The final prediction is usually obtained by averaging the predictions (for regression) or taking a majority vote (for classification).\n",
    "\n",
    "The most common example for such an ensemble model is the **Random Forest**.\n",
    "\n",
    "### Many Trees are a Forest: Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that combines multiple decision trees using bagging and random feature selection. Each tree is trained on a different bootstrap sample of the data, and a random subset of features is used for splitting nodes. The final prediction is made by averaging the predictions of all individual trees (for regression) or by majority voting (for classification).\n",
    "\n",
    "We could implement this by just combining multiple decision trees, for instance via the Scikit-Learn `BaggingClassifier` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09d4479-79be-4b75-86c1-cd9530687167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bagging Classifier: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Initialize base classifier\n",
    "base_clf = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "# Initialize bagging classifier\n",
    "bagging_clf = BaggingClassifier(estimator=base_clf, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the bagging classifier\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of Bagging Classifier: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6f2a9-3fe6-4ff8-a65a-fc3ff1cb15a7",
   "metadata": {},
   "source": [
    "However, the **Random Forest** is famous enough to be implemented already in Scikit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "743dc702-131e-4269-a1f5-95a18f280b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(max_depth=6, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of Random Forest Classifier: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490ba97-82eb-4dc6-b928-3dfc5faa49aa",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "Boosting is another ensemble technique that focuses on training models sequentially. Each new model attempts to correct the errors made by the previous ones. This way, the models \"boost\" the performance by focusing more on the difficult cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "579e7ef3-2424-44c5-98e0-5c1ea31ceab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AdaBoost Classifier: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize base classifier\n",
    "base_clf = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(estimator=base_clf, n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the AdaBoost classifier\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy of AdaBoost Classifier: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d6e04-252b-4cd6-b3fd-e164d6c35282",
   "metadata": {},
   "source": [
    "## Outlook: More on Machine Learning\n",
    "\n",
    "This course is meant as a general introduction to data science. Machine Learning is, no doubt, one of the most essential tools for any data scientist to know about. In fact, it is not just one tool but an entire toolbox full of very powerful methods. It is important to know at least common examples of the most prominent types of tools, including unsupervised methods such as clustering techniques and dimensionality reduction, as well as supervised methods like k-nearest neighbors, linear regression, or decision trees.\n",
    "\n",
    "However, this will just give you a first impression of what is possible with machine learning. In addition, we will focus on a basic intuition and first application of these methods. We will not cover all algorithms in full depth.\n",
    "\n",
    "To deepen your understanding of individual methods and broaden your knowledge on various techniques, you might want to explore further. This includes the large field of deep learning, which we cannot cover in this course.\n",
    "\n",
    "### Further Learning Resources\n",
    "\n",
    "**Online courses and tutorials:**  \n",
    "There are many, in fact probably too many, courses and tutorials out there. One of them that is clearly a long time recommendation is Andrew Ng's open online courses such as the [Machine Learning Introduction on coursera](https://www.coursera.org/specializations/machine-learning-introduction).\n",
    "\n",
    "**Books on Machine Learning and Deep Learning:**  \n",
    "- \"Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python\" {cite}`raschka2022machine`\n",
    "- \"Understanding Deep Learning\" by Simon Prince, MIT Press, 2023 {cite}`prince2023understanding`\n",
    "\n",
    "By continuing to explore these resources, you can build a solid foundation in machine learning and stay up-to-date with the latest advancements in the field.\n",
    "\n",
    "Happy (machine) learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63299a6-d61f-4197-bea8-4a8d463ed1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
