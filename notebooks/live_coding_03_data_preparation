{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5833a515-72ef-43f0-8be4-4601a24ae0be",
   "metadata": {},
   "source": [
    "# Introduction to Data Pre-Processing\n",
    "\n",
    "## What is Data Pre-Processing?\n",
    "\n",
    "We have now arrived what we called *Scrub Data* in the **ASEMIC** data science workflow.\n",
    "More formally, this is usually termed **Data Pre-Processing** and is a crucial step in every data science project. This process involves the preparation and cleansing of raw data to make it suitable for further analysis and modeling. In essence, data pre-processing is about transforming raw data into a clean dataset that is free from errors, inconsistencies, and is formatted appropriately for use in analytics applications.\n",
    "\n",
    "The necessity for data pre-processing arises from the fact that real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends. Data might also be contaminated by errors or outliers that could potentially skew the results of any analysis performed.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "An often-heard quote in data science, most frequently in machine learning, is:  \n",
    "*Garbage in, garbage out!*  \n",
    "This phrase underscores a crucial truth about data science: the quality of the output is heavily dependent on the quality of the input. With a huge range of sophisticated tools and techniques available today, there is a common misconception that these tools can automatically correct or overcome shortcomings in the data. While modern technologies such as machine learning and artificial intelligence are powerful in extracting patterns and making predictions, they are not capable of performing miracles. Poor-quality data will likely result in poor-quality insights, leading to decisions that could be misleading or even detrimental.\n",
    "\n",
    "Therefore, investing time in data pre-processing not only enhances the reliability of your data but also significantly boosts the effectiveness of the analytical models that process this data. This step ensures that subsequent analyses are both accurate and robust, providing meaningful insights that are based on a solid foundation of clean and well-structured data. \n",
    "\n",
    "Data pre-processing is usually perceived as a much less \"shiny\" part of a data science process when compared to more \"fancy\" steps such as data visualization or training a machine learning model. It is not uncommon though, that the data acquisition and data preparation phase is what ultimately determines if a project will be a huge success or a failure!\n",
    "\n",
    "### Steps in Data Pre-Processing\n",
    "\n",
    "The process of data pre-processing includes several key steps:\n",
    "\n",
    "1. **Handling Missing Data**: Filling or removing data entries that are missing to prevent errors in analysis.\n",
    "2. **Data Integration**: Combining data from multiple sources to create a comprehensive dataset.\n",
    "3. **Data Transformation**: Normalizing, scaling, or converting data to ensure that the dataset has a consistent scale and format.\n",
    "4. **Data Cleaning**: Removing noise and correcting inconsistencies, which may involve addressing outliers, duplicate data, and correcting typos.\n",
    "5. **Data Reduction**: Reducing the complexity of data, which can involve decreasing the number of features in a dataset or modifying the dataset to focus on important attributes.\n",
    "\n",
    "These steps help in transforming raw data into a refined format that enhances the analytical capabilities of data science tools, leading to more accurate and insightful outcomes.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3f260-b884-416a-bb92-fc5d764f9c4f",
   "metadata": {},
   "source": [
    "## Dealing with Missing Values\n",
    "\n",
    "### Understanding Missing Values\n",
    "\n",
    "Missing data is a prevalent issue in most data gathering processes. It can occur for a variety of reasons including errors in data entry, failures in data collection processes, or during data transmission. The presence of missing values can significantly impact the performance of data analysis models, as most algorithms are designed to handle complete datasets.\n",
    "\n",
    "Handling missing data is therefore a crucial step; if not addressed properly, it can lead to biased or invalid results. Different strategies can be employed depending on the nature of the data and the intended analysis.\n",
    "\n",
    "### Techniques to Handle Missing Values\n",
    "\n",
    "#### 1. Deletion\n",
    "\n",
    "- **Listwise Deletion**: This involves removing any data entries that contain a missing value. While straightforward, this method can lead to a significant reduction in data size, which might not be ideal for statistical analysis.\n",
    "- **Pairwise Deletion**: Used primarily in statistical analyses, this method only excludes missing data in calculations where it is relevant. This allows for the use of all available data, although it can complicate the analysis process.\n",
    "\n",
    "#### 2. Imputation\n",
    "\n",
    "Imputation means that we try to make good guesses of what the missing data *could have been*. It therefore is about much more than just spending a bit more time compared to a simple deletion step. Whether or not it is appropriate to use imputation depends on how well we understand the data and how sensitive the following data science tasks are.\n",
    "If we, or the experts we collaborate with, do not have a very solid understanding of the data, its meaning, its measurement process etc., we should usually not include imputation since there is a very high risk that we create artifacts in the data that we are now aware of. \n",
    "\n",
    "The same is true if the following analysis is very sensible and thus requires properly measures values.\n",
    "\n",
    "In other cases, however, imputation can indeed improve later results because it might allow us to work with a larger part of the available data. Common imputation types are:\n",
    "\n",
    "- **Mean/Median/Mode Imputation**: This is one of the simplest methods where missing values are replaced with the mean, median, or mode of the respective column. It's quick and easy but can introduce bias if the data is not normally distributed.\n",
    "- **Predictive Models**: More sophisticated methods involve using statistical models, such as regression, to estimate missing values based on other data points within the dataset.\n",
    "- **K-Nearest Neighbors (KNN)**: This method imputes values based on the similarity of instances that are nearest to each other. It is more computationally intensive but can provide better results for complex datasets.\n",
    "\n",
    "### Python Examples: Handling Missing Values\n",
    "\n",
    "We will include detailed Python examples demonstrating these techniques, showing practical implementations using libraries such as `pandas` and `scikit-learn`. This hands-on approach will help in solidifying the theoretical concepts discussed and provide learners with the tools they need to effectively handle missing data in their projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f912e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "data1 = np.random.gamma(50, 2, 2000)\n",
    "data2 = np.random.gamma(100, 2, 1000)\n",
    "data = np.concatenate((data1, data2)) - 134\n",
    "\n",
    "plot_dist(data, 30, [\"mean\", \"median\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7bcbb",
   "metadata": {},
   "source": [
    "Here again: If you look at the distribution plot with the median and the mean, which of the two measures is better in this case (and why)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fa04e3-b8f0-4aea-b790-fb63ae0a9be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>30.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diane</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age   Salary\n",
       "0  Alice  25.0  50000.0\n",
       "1    Bob   NaN      NaN\n",
       "2         30.0  60000.0\n",
       "3  Diane  28.0  52000.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data\n",
    "data = {'Name': [\"Alice\", \"Bob\", \"\", \"Diane\"],\n",
    "        'Age': [25, np.nan, 30, 28],\n",
    "        'Salary': [50000, None, 60000, 52000]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5426b-d2c8-4e53-a4ea-71b458f541c4",
   "metadata": {},
   "source": [
    "We here have several missing values in our data.\n",
    "A problem we commonly face is that *missing* values can mean different things. In the technical sense, this simply means that there is no value at all. This is represented by `NaN` (= *Not a Number*) entries, such as `np.nan` in Numpy. But there are many different ways to represent missing data, which can easily lead to a lot of confusion. Pandas, for instance, also has options such as `NA` (see [Pandas documentation on missing values](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#na-semantics)). `None` is also commonly used to represent a non-existing or non-available entry. \n",
    "\n",
    "The most problematic entry representing missing data, are custom codes. Some devices, for instance, add values such as `9999` if a measurement is not possible. Or look at the table above in the code example, where an obviously missing name is represented by an empty string (`\"\"`). In a similar fashion you will get data with values such as `\"N/A\"`, `\"NA\"`, `\"None\"`, `\"unknown\"`, `\"missing\"` and countless others.\n",
    "\n",
    "For a human reader that might not seem too difficult at first. However, datasets will often be huge and we don't want to (or simply cannot) inspect all those options manually. In practice, this can make it surprisingly difficult to spot all missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370c649d-9c98-42d9-9691-5b8520238ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Name    4 non-null      object \n",
      " 1   Age     3 non-null      float64\n",
      " 2   Salary  3 non-null      float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500c565-06e4-4993-92d5-7279c04ea4e9",
   "metadata": {},
   "source": [
    "The `.info()` method is a very easy and quick way to check for missing entries. But it won't work for string-entries of any type, so that it here misses the empty entry in the \"Name\" column! For Pandas, this column has 4 entries and all are \"non-null\" which means \"not missing\". Simply because there *is* a value in every row, even if one of them is a probably undesired `\"\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1444d-5473-48c6-a08e-b4529e328399",
   "metadata": {},
   "source": [
    "### Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c9d8e8b-ee2a-4f41-951d-44a5ce97b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropna():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>30.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diane</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age   Salary\n",
       "0  Alice  25.0  50000.0\n",
       "2         30.0  60000.0\n",
       "3  Diane  28.0  52000.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing any rows that have at least one missing value\n",
    "clean_df = df.dropna()\n",
    "print(\"DataFrame after dropna():\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb296a-02f7-492b-85dd-5d6781e7d4e0",
   "metadata": {},
   "source": [
    "Very often, just like in this case, we have to find our own work-arounds for the data we get. Here, we could use a simple mask to remove names that we found to be represented by certain strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81c7fc85-fa20-4e9b-a7ce-389227d53c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, True]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x not in [\"\", \"unknown\", \"missing\", \"None\"] for x in df.Name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f394cb5-3d3e-4a16-84bd-3f420309cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diane</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age   Salary\n",
       "0  Alice  25.0  50000.0\n",
       "1    Bob   NaN      NaN\n",
       "3  Diane  28.0  52000.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = [x not in [\"\", \"unknown\", \"missing\", \"None\"] for x in df.Name]\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45fa95e4-ec7c-4bd6-b457-4397c146eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after Listwise Deletion:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diane</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age   Salary\n",
       "0  Alice  25.0  50000.0\n",
       "3  Diane  28.0  52000.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing any rows that have at least one missing value\n",
    "clean_df = df[mask]\n",
    "clean_df = clean_df.dropna()\n",
    "print(\"DataFrame after deletions:\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97176246-98b4-43bd-9227-6a630f825f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after KNN Imputation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.666667</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age   Salary\n",
       "0  25.000000  50000.0\n",
       "1  27.666667  54000.0\n",
       "2  30.000000  60000.0\n",
       "3  28.000000  52000.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Creating the imputer object\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Assuming df is a DataFrame containing the relevant features\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df[['Age', 'Salary']]), columns=['Age', 'Salary'])\n",
    "print(\"DataFrame after KNN Imputation:\")\n",
    "df_filled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b310a-b96c-450a-8ea1-eeb76b2c3961",
   "metadata": {},
   "source": [
    "## Combining Datasets\n",
    "\n",
    "### Why Combine Datasets?\n",
    "\n",
    "In many real-world data science scenarios, data doesn't come in a single, comprehensive package. Instead, relevant information is often scattered across multiple datasets. Combining these datasets is a crucial step as it enables a holistic analysis, providing a more complete view of the data subjects. Whether it's merging customer information from different branches of a company, integrating sales data from various regions, or linking patient data from multiple clinical studies, effectively combining datasets can yield insights that aren't observable in isolated data.\n",
    "\n",
    "At first, this seems to a be a rather simple operations. In practice, however, this is often surprisingly complicated and critical. If merging is not done correctly, we might either lose data or create incorrect entries.\n",
    "\n",
    "```\n",
    ":name: fig_data_merging01\n",
    "\n",
    "There are different type of merging data. Which one to use is best decided based on the data we have at hand and the types of operations we plan to run with the resulting data. Here are three of the most common types of merges: inner, left, and outer merges.\n",
    "```\n",
    "Figure ({numref}`fig_data_merging01`) shows some common merging types. More information on different ways to combine data using pandas can be found in the [pandas documentation on merging](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html). \n",
    "\n",
    "### Understanding Different Types of Merges\n",
    "\n",
    "Combining datasets effectively requires understanding the nature of the relationships between them. This understanding guides the choice of merging technique, each of which can affect the outcome of the analysis differently.\n",
    "\n",
    "#### Common Types of Merges\n",
    "\n",
    "1. **Inner Join**  \n",
    "**Description**: The inner join returns only those records that have matching values in both datasets. This method is most useful when you need to combine records that have a direct correspondence in both sources.  \n",
    "**Use Case**: Analyzing data where only complete records from both datasets are necessary, such as matching customer demographics with their purchasing records.\n",
    "\n",
    "3. **Outer Join**  \n",
    "Types:  \n",
    "     - **Full Outer Join**: Combines all records from both datasets, filling in missing values with NaNs where no match is found.\n",
    "     - **Left Outer Join**: Includes all records from the left dataset and the matched records from the right dataset.\n",
    "     - **Right Outer Join**: Includes all records from the right dataset and the matched records from the left dataset.\n",
    "\n",
    "   **Use Case**: Useful when you want to retain all information from one or both datasets, filling gaps with missing values for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846f282-48eb-4c92-a2d4-08191c34aec3",
   "metadata": {},
   "source": [
    "To illustrate these concepts, let's see practical examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0153d3bb-95f3-486f-9dd3-f3e3cf9189da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Widget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Gadget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>DoesWhat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>DoSomething</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  ProductName\n",
       "0        101       Widget\n",
       "1        102       Gadget\n",
       "2        103     DoesWhat\n",
       "3        104  DoSomething"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample data for products\n",
    "data_products = pd.DataFrame({\n",
    "    'ProductID': [101, 102, 103, 104],\n",
    "    'ProductName': ['Widget', 'Gadget', 'DoesWhat', 'DoSomething']\n",
    "})\n",
    "\n",
    "# Create sample data for sales\n",
    "data_sales = pd.DataFrame({\n",
    "    'ProductID': [101, 102, 104, 105],\n",
    "    'UnitsSold': [134, 243, 76, 100]\n",
    "})\n",
    "data_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac68858b-9b6b-4610-8e8a-059af1bdc05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>UnitsSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  UnitsSold\n",
       "0        101        134\n",
       "1        102        243\n",
       "2        104         76\n",
       "3        105        100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f9d68-132f-41fc-bac8-846d704cd7d5",
   "metadata": {},
   "source": [
    "Inner Join Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac256f7d-b52b-4537-b926-5476d31024e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join Result:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>UnitsSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Widget</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>DoSomething</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  ProductName  UnitsSold\n",
       "0        101       Widget        134\n",
       "1        102       Gadget        243\n",
       "2        104  DoSomething         76"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_join_df = pd.merge(data_products, data_sales, on='ProductID', how='inner')\n",
    "print(\"Inner Join Result:\")\n",
    "inner_join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef39c3-e8fb-4f19-8b99-66d87dca5cdf",
   "metadata": {},
   "source": [
    "Left outer join and full outer join examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4735bb9d-849b-4c41-9ffb-d3f4df41243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Outer Join Result:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>UnitsSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Widget</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>DoesWhat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>DoSomething</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  ProductName  UnitsSold\n",
       "0        101       Widget      134.0\n",
       "1        102       Gadget      243.0\n",
       "2        103     DoesWhat        NaN\n",
       "3        104  DoSomething       76.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_outer_join_df = pd.merge(data_products, data_sales, on='ProductID', how='left')\n",
    "print(\"Left Outer Join Result:\")\n",
    "left_outer_join_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a90b0b5-5539-4c44-9aa8-0587d3e30518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Outer Join Result:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>UnitsSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Widget</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Gadget</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>DoesWhat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>DoSomething</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  ProductName  UnitsSold\n",
       "0        101       Widget      134.0\n",
       "1        102       Gadget      243.0\n",
       "2        103     DoesWhat        NaN\n",
       "3        104  DoSomething       76.0\n",
       "4        105          NaN      100.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_outer_join_df = pd.merge(data_products, data_sales, on='ProductID', how='outer')\n",
    "print(\"Full Outer Join Result:\")\n",
    "full_outer_join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82bd00-26da-4ce9-b200-2f5a9ad96694",
   "metadata": {},
   "source": [
    "### Typical Challenges:\n",
    "The given example is fairly simple. In practice, you will often face far more complex situation that often require specific work-arounds. Some very common challenges for merging data are:\n",
    "\n",
    "- **Duplicates**: Data can have repeated or conflicting entries.\n",
    "- **Inconsistent Nomenclature**: Consistency in naming conventions can save hours of data wrangling later on. A classic example being different formats of names. \"First Name Last Name\" versus \"Last Name, First Name\".\n",
    "\n",
    "It is therefore often a good strategy to work with a good identifier system where every datapoint is linked to one specific, unique ID. This can be a number, a hash, a specific code, a filename etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6c2fe3-ba5e-4d9c-9ebc-d778df45b6be",
   "metadata": {},
   "source": [
    "## Further Cleaning Steps:\n",
    "\n",
    "- **Unit Conversion**: Ensuring data is in consistent units.\n",
    "- **Data Standardization**: This can be done via Min-Max scaling (often termed \"normalization\") or, frequently more effective, by ensuring data has a mean of 0 and a standard deviation of 1.\n",
    "- **Non-linear Transformations**: Sometimes, linear thinking won't do. Transformations like logarithms can provide new perspectives on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ad22f-6d45-4c67-acc6-7c5566ed1fd0",
   "metadata": {},
   "source": [
    "- **Data Types**: Ensuring that numeric values aren't masquerading as strings can prevent potential analytical blunders (e.g., \"12.5\" instead of 12.5).\n",
    "- **Decimal Delimiters**: Confusion between comma and dot can change data meaning, e.g., 12,010 becoming 12.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0f08d-ee79-4ace-9d31-4548a2e18616",
   "metadata": {},
   "source": [
    "## Data Conversion and Formatting\n",
    "\n",
    "### Importance of Proper Data Types and Consistent Formatting\n",
    "\n",
    "Data types and formatting play a critical role in the accuracy and efficiency of data analysis. Incorrect data types or inconsistent formatting can lead to errors or misinterpretations during data processing. For instance, numeric values stored as strings may not be usable for calculations without conversion, and date strings may be misinterpreted if their format is not uniformly recognized. Ensuring data is correctly typed and formatted is crucial for:\n",
    "\n",
    "- **Data Quality**: Correct types and formats ensure that the data adheres to the expected standards, improving the overall quality and reliability of the dataset.\n",
    "- **Analytical Accuracy**: Proper data types are essential for performing accurate mathematical and statistical calculations.\n",
    "- **Operational Efficiency**: Operations on data, such as sorting and indexing, are more efficient when data types are appropriately set.\n",
    "\n",
    "### Converting Data Types in Pandas\n",
    "\n",
    "Pandas provides robust tools for converting data types, which is often necessary when data is imported from different sources and formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df659563-cca1-41b9-84aa-49e73ef107ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after conversion:\n",
      "   ProductID  Price        Date\n",
      "0          1  12.50  2021-01-01\n",
      "1          2  15.00  2021-01-02\n",
      "2          3  20.25  2021-01-03\n"
     ]
    }
   ],
   "source": [
    "# Sample data with incorrect data types\n",
    "data = pd.DataFrame({\n",
    "    'ProductID': ['001', '002', '003'],\n",
    "    'Price': ['12.5', '15.0', '20.25'],\n",
    "    'Date': ['2021-01-01', '2021-01-02', '2021-01-03']\n",
    "})\n",
    "\n",
    "# Convert 'ProductID' to integer\n",
    "data['ProductID'] = data['ProductID'].astype(int)\n",
    "\n",
    "# Convert 'Price' to float\n",
    "data['Price'] = data['Price'].replace(',', '.').astype(float)\n",
    "\n",
    "print(\"Data after conversion:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb93ad2-0b91-4f2b-830c-f981ae340aaf",
   "metadata": {},
   "source": [
    "### Formatting Data\n",
    "\n",
    "Proper formatting involves converting data into a consistent and usable format. This includes date-time conversion, string manipulation, and handling decimal delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1098ee4b-3c7d-444d-8641-94591b0439c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after formatting Date:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.50</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2021-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20.25</td>\n",
       "      <td>2021-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID  Price       Date\n",
       "0          1  12.50 2021-01-01\n",
       "1          2  15.00 2021-01-02\n",
       "2          3  20.25 2021-01-03"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Date' to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "print(\"Data after formatting Date:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1af07e-23a6-444b-987b-4485e52b9385",
   "metadata": {},
   "source": [
    "#### Example: Handling Decimal Delimiters\n",
    "\n",
    "This example demonstrates how to handle a common issue where decimal delimiters vary between commas and dots, which can lead to misinterpretation of numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64786ba6-bd9f-4104-b0fb-074e60c5a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Sales Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>10000.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU</td>\n",
       "      <td>8000.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>1000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region     Sales\n",
       "0     US  10000.50\n",
       "1     EU   8000.75\n",
       "2     IN   1000.00"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data with decimal confusion\n",
    "sales_data = pd.DataFrame({\n",
    "    'Region': ['US', 'EU', 'IN'],\n",
    "    'Sales': ['10,000.50', '8.000,75', '1,000.00']\n",
    "})\n",
    "\n",
    "# Correcting decimal delimiters based on region\n",
    "sales_data['Sales'] = sales_data.apply(\n",
    "    lambda row: row['Sales'].replace('.', '').replace(',', '.') if row['Region'] == 'EU' else row['Sales'].replace(',', ''),\n",
    "    axis=1\n",
    ").astype(float)\n",
    "\n",
    "print(\"Corrected Sales Data:\")\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139bce48-29bf-4ec1-a14a-18cb967fbc87",
   "metadata": {},
   "source": [
    "#### String Manipulation\n",
    "\n",
    "Handling strings effectively can also play a crucial part in cleaning data, such as trimming extra spaces, correcting typos, and standardizing text formats. String handling in Pandas mostly works just as in regular Python. By using `.str` we can access columns in a dataframe and apply specific string methods such as `.strip()` or `.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68867791-4cbf-40cf-bc0f-a2adfbf80f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Customer Names:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CustomerName\n",
       "0        Alice\n",
       "1          Bob\n",
       "2      Charles"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data with string inconsistencies\n",
    "customer_data = pd.DataFrame({\n",
    "    'CustomerName': [' Alice ', 'bob', 'CHARLES']\n",
    "})\n",
    "\n",
    "# Standardizing string format: trim, lower case, capitalize\n",
    "customer_data['CustomerName'] = customer_data['CustomerName'].str.strip().str.lower().str.capitalize()\n",
    "\n",
    "print(\"Standardized Customer Names:\")\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7dc704-2d91-4d66-84cb-3014911cfae4",
   "metadata": {},
   "source": [
    "## Further Cleaning Steps\n",
    "### Removing Duplicates\n",
    "\n",
    "Duplicate entries in a dataset can skew analysis and lead to incorrect conclusions.\n",
    "It's often important to identify and remove duplicates to ensure data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03e249c5-051e-4506-97d4-d079e32a70a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>PurchaseAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dave</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID     Name  PurchaseAmount\n",
       "0           1    Alice             250\n",
       "1           2      Bob             150\n",
       "2           2      Bob             150\n",
       "3           3  Charlie             300\n",
       "4           4     Dave             400"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data with duplicate entries\n",
    "data = pd.DataFrame({\n",
    "    'CustomerID': [1, 2, 2, 3, 4, 4, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Bob', 'Charlie', 'Dave', 'Dave', 'Dave'],\n",
    "    'PurchaseAmount': [250, 150, 150, 300, 400, 400, 400]\n",
    "})\n",
    "\n",
    "print(\"Original Data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2a2d238-0661-495d-98b7-9cf720814f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Removing Duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>PurchaseAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Dave</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID     Name  PurchaseAmount\n",
       "0           1    Alice             250\n",
       "1           2      Bob             150\n",
       "3           3  Charlie             300\n",
       "4           4     Dave             400"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing duplicates\n",
    "data_unique = data.drop_duplicates()\n",
    "print(\"Data after Removing Duplicates:\")\n",
    "data_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c4b06-d5ed-4276-ade7-83cc63f0ed0a",
   "metadata": {},
   "source": [
    "### Standardizing Data\n",
    "\n",
    "Data standardization involves rescaling the values to a standard, such as having a mean of zero and a standard deviation of one (z-score standardization), or scaling data to a fixed range like 0 to 1 (normalization). This is crucial for many algorithms, including many algorithms in dimensionality reduction, clustering or many machine learning. We will therefore skip this for now, and address this question in later chapters where this processing step becomes crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f69c6-ad33-4ef0-ae2d-cb04b5abf216",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In essence, data acquisition and preparation are the unsung heroes of a successful data science endeavor. By ensuring the foundation is robust and the raw materials are of top quality, you set the stage for analytical brilliance.\n",
    "\n",
    "From my own experience: It is not uncommon that 80% of the work in a data science project goes into the data acquisition and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74328f7-9b5a-4dc5-9a27-eca33eca987a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
